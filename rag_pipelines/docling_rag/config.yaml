vision_llm:
    model_id: "meta-llama/llama-4-scout-17b-16e-instruct"
    max_tokens: 500
    temperature: 0
    top_p: 0.1
    stop_sequences: []
answer_llm:
    model_id: "meta-llama/llama-4-scout-17b-16e-instruct"
    max_tokens: 500
    temperature: 0
    top_p: 0.1
    stop_sequences: []
vector_db:
    embedding_modelname: "intfloat/multilingual-e5-small"
    collection_name: "chroma_collection_multimodal"
    persist_directory: "./chroma_db"
multimodal_reader:
    context_window: 4
    max_workers: 32
    group_mode: "group_by_title"
    keep_images_tables_separate: false
chunking:
    chunk_size: 512
    chunk_overlap: 50
    separators: ["\n\n", " "]